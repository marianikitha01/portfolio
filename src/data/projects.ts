
import type { Project } from '@/lib/types';

export const projects: Project[] = [
  {
    id: 'chikankari-design-generator',
    title: 'Chikankari Design Generator using Generative AI',
    description: 'Built a generative pipeline using Stable Diffusion v1.5 fine-tuned with Advanced LoRA to synthesize authentic Chikankari embroidery pattern designs.',
    longDescription: 'This capstone project involved building a generative pipeline using Stable Diffusion v1.5 fine-tuned with Advanced LoRA on 4000+ Chikankari embroidery images. Developed training workflows with Hugging Face Diffusers, including data augmentation, checkpointing, and LoRA adaptation. Evaluated model performance using FID and CLIPScore to assess realism and prompt alignment. Designed and implemented a user interface with Streamlit that allows users to input custom prompts and generate embroidery patterns, making the tool accessible for non-technical users.',
    imageUrl: '/chikankari1.png',
    imageHint: 'embroidery art',
    tags: ['Generative AI', 'Stable Diffusion', 'LoRA', 'Hugging Face', 'Streamlit', 'Python', 'Capstone'],
    codeLink: 'https://github.com/INFO-698-InfoSci-Capstone/cultural-heritage-ai',
    liveDemoLink: '#',
    category: 'Generative AI',
  },
  {
    id: 'early-readmission-prediction',
    title: 'Early Readmission Prediction (AWS & ML)',
    description: 'Developed an ML model (Random Forest) to predict early hospital readmissions (89% test accuracy) with an AWS-based ETL pipeline using Glue.',
    longDescription: 'Developed a machine learning model to predict early hospital readmissions using a Random Forest Classifier, achieving a training accuracy of 96% and a test accuracy of 88.99%. Implemented an ETL pipeline on AWS to automate data extraction, transformation, and loading processes, utilizing AWS Glue for data cataloging and ETL operations. Performed data preprocessing and oversampling techniques, specifically using SMOTE, to address class imbalance in the dataset, enhancing model performance.',
    imageUrl: '/early.png',
    imageHint: 'hospital analytics',
    tags: ['Machine Learning', 'Random Forest', 'SMOTE', 'AWS', 'ETL', 'AWS Glue', 'Python'],
    codeLink: 'https://github.com/marianikitha01/Early_Readmission',
    liveDemoLink: '#',
    category: 'Machine Learning',
  },
  {
    id: 'ecommerce-azure-pipeline',
    title: 'E-Commerce Data Pipeline (Azure)',
    description: 'Designed and implemented an end-to-end data pipeline for E-commerce data using Azure Data Lake, Data Factory, and Databricks with Spark.',
    longDescription: 'Designed and implemented an end-to-end data pipeline using Azure Data Lake Storage, Azure Data Factory, and Azure Databricks. Ingested E-commerce data from multiple sources into Azure Data Lake and developed ETL workflows in Azure Data Factory for data extraction, transformation, and loading. Utilized Apache Spark on Azure Databricks for processing large-scale data, following Bronze, Silver, and Gold architecture. Leveraged Delta Lake for optimized storage, data versioning, and reliability. Implemented data quality checks and performance optimizations to enhance efficiency.',
    imageUrl: '/ecommerce.png',
    imageHint: 'data pipeline',
    tags: ['Data Engineering', 'Azure', 'ADLS', 'Data Factory', 'Databricks', 'Spark', 'Delta Lake', 'ETL'],
    codeLink: 'https://github.com/marianikitha01/Ecom_Data_Analysis',
    liveDemoLink: '#',
    category: 'Data Engineering',
  },
  {
    id: 'spotify-aws-pipeline',
    title: 'Spotify Data Engineering Pipeline (AWS)',
    description: 'Designed a serverless ETL pipeline using AWS Lambda and Python to extract, transform, and load Spotify API data into Amazon S3 for analysis.',
    longDescription: 'Designed and deployed a serverless ETL pipeline using AWS Lambda and Python to extract, transform, and load Spotify API data into Amazon S3. Registered data with AWS Glue and performed analysis using AWS Athena to derive trends in user behavior and consumption patterns. Implemented automated triggers for continuous data updates and added data validation layers to ensure high-quality ingestion.',
    imageUrl: '/spotify.png',
    imageHint: 'music data',
    tags: ['Data Engineering', 'AWS Lambda', 'S3', 'AWS Glue', 'Athena', 'Python', 'ETL', 'API'],
    codeLink: '#', // Link was not explicitly provided for this project.
    liveDemoLink: '#',
    category: 'Data Engineering',
  },
  {
    id: 'aapl-stock-dashboard-powerbi',
    title: 'AAPL Stock Analytics Dashboard (Power BI)',
    description: 'Developed a Python data pipeline and an interactive Power BI dashboard for AAPL stock analytics, including Prophet price forecasts.',
    longDescription: 'Developed a Python-based data pipeline to automate daily OHLC retrieval from Alpha Vantage, enhancing datasets with RSI, MACD, and 30-day moving averages using Pandas. Performed statistical time series analysis in Jupyter and trained a Prophet model to generate 30-day price forecasts with confidence intervals, transforming raw outputs into business-ready insights for BI consumption. Built dynamic DAX measures in Power BI, including Latest Close, Daily % Change, YTD Return, and Predicted Price. Designed a dark-themed, interactive dashboard published to Power BI Service with scheduled refresh.',
    imageUrl: '/aapl1.jpg',
    imageHint: 'stock market',
    tags: ['Data Visualization', 'Power BI', 'Python', 'Pandas', 'Prophet', 'DAX', 'Time Series', 'API'],
    codeLink: 'https://github.com/marianikitha01/Interactive_stock_market_dashboard_with_AAPL',
    liveDemoLink: '#',
    category: 'Data Visualization',
  },
  {
    id: 'soybean-deforestation-analysis',
    title: 'Soybean Consumption & Deforestation Analysis',
    description: 'Analyzed soybean consumption trends in Brazil (1990-2013) and its impact on deforestation using R and ggplot2.',
    longDescription: 'Conducted a comprehensive analysis of soybean consumption trends in Brazil from 1990 to 2013, utilizing datasets from Our World in Data to calculate total usage using R. Preprocessed data to filter for relevant years and regions, ensuring accuracy, and merged this data with forest coverage datasets to assess the implications of agricultural expansion on deforestation. Developed visualizations using ggplot2 to illustrate trends, identifying a significant correlation between increased soybean consumption and decreased forest coverage. Presented findings to stakeholders, emphasizing sustainable agricultural practices.',
    imageUrl: '/soybean1.png',
    imageHint: 'agriculture environment',
    tags: ['Data Analysis', 'Data Visualization', 'R', 'ggplot2', 'Environment', 'Sustainability'],
    codeLink: 'https://github.com/INFO526-DataViz/project-01-The-Plotting-Pandas',
    liveDemoLink: '#',
    category: 'Data Analysis',
  },
  {
    id: 'arizona-drought-shiny-app',
    title: 'Arizona Drought Data Exploration (Shiny App)',
    description: 'Developed an interactive Shiny web app to explore Arizona\'s drought data, featuring time series analysis and geospatial visualizations.',
    longDescription: 'Designed and developed an interactive Shiny web application to explore and communicate patterns in Arizona\'s drought data, aimed at supporting sustainable water resource management. Performed time series analysis to examine drought severity trends over time, visualized through stacked bar charts and line plots. Created interactive county-level maps and donut charts to highlight the regions most impacted by drought conditions. Developed seasonal visualizations using choropleth maps to uncover spatial and temporal drought patterns across the state.',
    imageUrl: '/arizona.png',
    imageHint: 'drought map',
    tags: ['Data Visualization', 'R', 'Shiny', 'Interactive Dashboard', 'Time Series', 'Geospatial'],
    codeLink: 'https://github.com/INFO526-DataViz/Drought-Prediction-in-AZ',
    liveDemoLink: '#',
    category: 'Data Visualization',
  },
];
