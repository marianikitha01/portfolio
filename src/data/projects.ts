
import type { Project } from '@/lib/types';

export const projects: Project[] = [
  {
    id: 'rag-bi-chatbot',
    title: 'RAG-Powered Conversational BI Chatbot using LangChain and GPT-4',
    description: 'Built an LLM-powered BI chatbot that enables natural language querying over tabular data using RAG architecture, FAISS, and GPT-4.',
    longDescription: 'Developed a Retrieval-Augmented Generation (RAG) based conversational chatbot to enable natural language queries over CSV files, showcasing practical applications of LLMs in business intelligence. Engineered a semantic search pipeline using Hugging Face Sentence Transformers and FAISS for vector indexing. Integrated LangChain and GPT-4 to deliver accurate, context-aware insights. Containerized the project with Docker for seamless deployment and reproducibility.',
    imageUrl: '/rag-bot.png',
    imageHint: 'chat interface with data analysis',
    tags: ['LLM', 'LangChain', 'RAG', 'GPT-4', 'FAISS', 'Hugging Face', 'Generative AI', 'Docker', 'NLP'],
    codeLink: 'https://github.com/marianikitha01/RAG-Powered-Conversational-BI-Chatbot',
    liveDemoLink: '#',
    category: 'LLM Applications',
  },
  {
    id: 'feature-rollout-ab-test',
    title: 'Feature Rollout Impact Analysis (A/B Testing, SQL, Azure DevOps)',
    description: 'Designed and executed end-to-end A/B testing for a simulated SaaS product using SQL, statistical analysis, and DevOps best practices.',
    longDescription: 'Built an industry-level A/B testing project to measure the impact of a new feature rollout in a subscription-based SaaS environment. Used PostgreSQL for behavioral analysis, applying advanced SQL techniques such as window functions, cohort retention, and user-defined functions. Validated experimental outcomes with Python statistical tests (t-tests, chi-square) to evaluate conversion, churn, and satisfaction. Simulated Agile workflows using Azure DevOps Boards with structured Epics, Features, and Tasks. Integrated Git with Azure Pipelines to implement a CI/CD workflow for reproducible analysis and automation.',
    imageUrl: '/feature-rollout.png', 
    imageHint: 'A/B testing dashboard with churn and retention metrics',
    tags: ['SQL', 'A/B Testing', 'Data Analysis', 'PostgreSQL', 'Azure DevOps', 'CI/CD', 'Python', 'Experiment Design'],
    codeLink: 'https://github.com/marianikitha01/feature-rollout-impact-analysis',
    liveDemoLink: '#',
    category: 'Data Analysis',
  },
  {
    id: 'chikankari-design-generator',
    title: 'Chikankari Design Generator using Generative AI',
    description: 'Built a generative pipeline using Stable Diffusion v1.5 fine-tuned with Advanced LoRA to synthesize authentic Chikankari embroidery pattern designs.',
    longDescription: 'This capstone project involved building a generative pipeline using Stable Diffusion v1.5 fine-tuned with Advanced LoRA on 4000+ Chikankari embroidery images. Developed training workflows with Hugging Face Diffusers, including data augmentation, checkpointing, and LoRA adaptation. Evaluated model performance using FID and CLIPScore to assess realism and prompt alignment. Designed and implemented a user interface with Streamlit that allows users to input custom prompts and generate embroidery patterns, making the tool accessible for non-technical users.',
    imageUrl: '/chikankari1.png',
    imageHint: 'embroidery art',
    tags: ['Generative AI', 'Stable Diffusion', 'LoRA', 'Hugging Face', 'Streamlit', 'Python', 'Capstone'],
    codeLink: 'https://github.com/INFO-698-InfoSci-Capstone/cultural-heritage-ai',
    liveDemoLink: '#',
    category: 'Generative AI',
  },
  {
    id: 'early-readmission-prediction',
    title: 'Early Readmission Prediction (AWS & ML)',
    description: 'Developed an ML model (Random Forest) to predict early hospital readmissions (89% test accuracy) with an AWS-based ETL pipeline using Glue.',
    longDescription: 'Developed a machine learning model to predict early hospital readmissions using a Random Forest Classifier, achieving a training accuracy of 96% and a test accuracy of 88.99%. Implemented an ETL pipeline on AWS to automate data extraction, transformation, and loading processes, utilizing AWS Glue for data cataloging and ETL operations. Performed data preprocessing and oversampling techniques, specifically using SMOTE, to address class imbalance in the dataset, enhancing model performance.',
    imageUrl: '/early.png',
    imageHint: 'hospital analytics',
    tags: ['Machine Learning', 'Random Forest', 'SMOTE', 'AWS', 'ETL', 'AWS Glue', 'Python'],
    codeLink: 'https://github.com/marianikitha01/Early_Readmission',
    liveDemoLink: '#',
    category: 'Machine Learning',
  },
  {
    id: 'ecommerce-azure-pipeline',
    title: 'E-Commerce Data Pipeline (Azure)',
    description: 'Designed and implemented an end-to-end data pipeline for E-commerce data using Azure Data Lake, Data Factory, and Databricks with Spark.',
    longDescription: 'Designed and implemented an end-to-end data pipeline using Azure Data Lake Storage, Azure Data Factory, and Azure Databricks. Ingested E-commerce data from multiple sources into Azure Data Lake and developed ETL workflows in Azure Data Factory for data extraction, transformation, and loading. Utilized Apache Spark on Azure Databricks for processing large-scale data, following Bronze, Silver, and Gold architecture. Leveraged Delta Lake for optimized storage, data versioning, and reliability. Implemented data quality checks and performance optimizations to enhance efficiency.',
    imageUrl: '/ecommerce.png',
    imageHint: 'data pipeline',
    tags: ['Data Engineering', 'Azure', 'ADLS', 'Data Factory', 'Databricks', 'Spark', 'Delta Lake', 'ETL'],
    codeLink: 'https://github.com/marianikitha01/Ecom_Data_Analysis',
    liveDemoLink: '#',
    category: 'Data Engineering',
  },
  {
    id: 'spotify-aws-pipeline',
    title: 'Spotify Data Engineering Pipeline (AWS)',
    description: 'Designed a serverless ETL pipeline using AWS Lambda and Python to extract, transform, and load Spotify API data into Amazon S3 for analysis.',
    longDescription: 'Designed and deployed a serverless ETL pipeline using AWS Lambda and Python to extract, transform, and load Spotify API data into Amazon S3. Registered data with AWS Glue and performed analysis using AWS Athena to derive trends in user behavior and consumption patterns. Implemented automated triggers for continuous data updates and added data validation layers to ensure high-quality ingestion.',
    imageUrl: '/spotify.png',
    imageHint: 'music data',
    tags: ['Data Engineering', 'AWS Lambda', 'S3', 'AWS Glue', 'Athena', 'Python', 'ETL', 'API'],
    codeLink: '#', // Link was not explicitly provided for this project.
    liveDemoLink: '#',
    category: 'Data Engineering',
  },
  {
    id: 'aapl-stock-dashboard-powerbi',
    title: 'AAPL Stock Analytics Dashboard (Power BI)',
    description: 'Developed a Python data pipeline and an interactive Power BI dashboard for AAPL stock analytics, including Prophet price forecasts.',
    longDescription: 'Developed a Python-based data pipeline to automate daily OHLC retrieval from Alpha Vantage, enhancing datasets with RSI, MACD, and 30-day moving averages using Pandas. Performed statistical time series analysis in Jupyter and trained a Prophet model to generate 30-day price forecasts with confidence intervals, transforming raw outputs into business-ready insights for BI consumption. Built dynamic DAX measures in Power BI, including Latest Close, Daily % Change, YTD Return, and Predicted Price. Designed a dark-themed, interactive dashboard published to Power BI Service with scheduled refresh.',
    imageUrl: '/aapl1.png',
    imageHint: 'stock market',
    tags: ['Data Visualization', 'Power BI', 'Python', 'Pandas', 'Prophet', 'DAX', 'Time Series', 'API'],
    codeLink: 'https://github.com/marianikitha01/Interactive_stock_market_dashboard_with_AAPL',
    liveDemoLink: '#',
    category: 'Data Visualization',
  },
  {
  id: 'supply-chain-bottleneck-tableau',
  title: 'Supply Chain Bottleneck Explorer (Tableau)',
  description: 'Built an interactive Tableau dashboard to analyze supply chain delays and identify bottlenecks across manufacturing stages.',
  longDescription: 'Designed a stakeholder-facing Tableau dashboard using real-world logistics data to explore bottlenecks across Procurement, Production, Assembly, and QC stages. Cleaned and preprocessed 25K+ records using Python (Pandas), engineered KPIs such as lead time, defect rate, and delay probability. Developed 7+ interactive visualizations including KPI cards, defect trend analysis, delay distribution, and choropleth maps. Delivered key insights such as 76.5% defect rate and 26K+ port delay cases impacting on-time delivery.',
  imageUrl: '/supply_chain1.png',
  imageHint: 'logistics bottleneck',
  tags: ['Tableau', 'Data Visualization', 'Python', 'Pandas', 'Supply Chain', 'KPI Analysis', 'Manufacturing', 'Dashboard'],
  codeLink: 'https://github.com/marianikitha01/supply-chain-bottleneck-dashboard',
  liveDemoLink: 'https://public.tableau.com/app/profile/maria.nikitha.suresh/viz/Book1_17485785997010/Dashboard22',
  category: 'Data Visualization',
  },
  {
    id: 'soybean-deforestation-analysis',
    title: 'Soybean Consumption & Deforestation Analysis',
    description: 'Analyzed soybean consumption trends in Brazil (1990-2013) and its impact on deforestation using R and ggplot2.',
    longDescription: 'Conducted a comprehensive analysis of soybean consumption trends in Brazil from 1990 to 2013, utilizing datasets from Our World in Data to calculate total usage using R. Preprocessed data to filter for relevant years and regions, ensuring accuracy, and merged this data with forest coverage datasets to assess the implications of agricultural expansion on deforestation. Developed visualizations using ggplot2 to illustrate trends, identifying a significant correlation between increased soybean consumption and decreased forest coverage. Presented findings to stakeholders, emphasizing sustainable agricultural practices.',
    imageUrl: '/soybean1.png',
    imageHint: 'agriculture environment',
    tags: ['Data Analysis', 'Data Visualization', 'R', 'ggplot2', 'Environment', 'Sustainability'],
    codeLink: 'https://github.com/INFO526-DataViz/project-01-The-Plotting-Pandas',
    liveDemoLink: '#',
    category: 'Data Analysis',
  },
  {
    id: 'arizona-drought-shiny-app',
    title: 'Arizona Drought Data Exploration (Shiny App)',
    description: 'Developed an interactive Shiny web app to explore Arizona\'s drought data, featuring time series analysis and geospatial visualizations.',
    longDescription: 'Designed and developed an interactive Shiny web application to explore and communicate patterns in Arizona\'s drought data, aimed at supporting sustainable water resource management. Performed time series analysis to examine drought severity trends over time, visualized through stacked bar charts and line plots. Created interactive county-level maps and donut charts to highlight the regions most impacted by drought conditions. Developed seasonal visualizations using choropleth maps to uncover spatial and temporal drought patterns across the state.',
    imageUrl: '/arizona.png',
    imageHint: 'drought map',
    tags: ['Data Visualization', 'R', 'Shiny', 'Interactive Dashboard', 'Time Series', 'Geospatial'],
    codeLink: 'https://github.com/INFO526-DataViz/Drought-Prediction-in-AZ',
    liveDemoLink: '#',
    category: 'Data Visualization',
  },
];
